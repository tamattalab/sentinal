# ğŸ—ï¸ HONEYPOT-AGENT â€” System Architecture (v4.4.0 + SLM Layer 4D)

**Version**: 4.4.0  
**Design**: Rule-based pipeline + optional SmolLM2-135M-Instruct (Layer 4D)  
**Stack**: Python 3.12 Â· FastAPI Â· Torch/Transformers (optional)  
**Performance**: 1.5ms (SLM off) Â· <8s (SLM on) Â· 100/100 GUVI score

---

## ğŸ—ºï¸ 7-Layer Pipeline

```
Request â†’ Auth â†’ Parse â†’ Session â†’ [Scam Detect + Intel Extract + GNB Fraud + SLM] â†’ Reply Gen â†’ Response Build
           L1     L2       L3          L4A            L4B          L4C       L4D          L5           L6
```

| Layer | File | Purpose |
|---|---|---|
| **L1** (Auth) | `main.py` | x-api-key header validation |
| **L2** (Parse) | `main.py` | Tolerant JSON with multiple key fallbacks |
| **L3** (Session) | `session_manager.py` | In-memory state: turns, intel, dedup, timing |
| **L4A** (Scam) | `scam_detector.py` | 16-category weighted keywords + sigmoid confidence |
| **L4B** (Intel) | `intelligence.py` | 9 regex extractors (phone, UPI, bank, IFSC, URL, email, etc.) |
| **L4C** (Fraud) | `fraud_model.py` | GaussianNB (JP Morgan, 79.5% accuracy, 4 features) |
| **L4D** (SLM) | `slm_engine.py` | **NEW** SmolLM2-135M-Instruct refinement (optional) |
| **L5** (Reply) | `agent_persona.py` | 600+ templates, phase-rotation, dedup, red-flags, probes |
| **L6** (Build) | `main.py` | Assemble full rubric-compliant JSON response |

---

## ğŸ¤– Layer 4D: SLM Engine (SmolLM2-135M-Instruct)

### Architecture
- **Model**: HuggingFaceTB/SmolLM2-135M-Instruct (135M params, ~270MB)
- **Toggle**: `USE_SLM` env var (default `false`)
- **Execution**: Async via `asyncio.to_thread()` with 8s timeout
- **Fallback**: On timeout/error â†’ empty result, rules win

### What SLM Does
1. **Refine confidence**: Re-evaluates scam probability from message context + history
2. **Extract entities**: Finds entities missed by regex (e.g., implied UPI, paraphrased phone numbers)
3. **Generate reply**: Adapts template-based reply with contextual persona variation
4. **Behavioral insight**: Analyzes scammer tactics (sarcasm, escalation, new patterns)

### Merge Strategy
```
confidence = max(rule_confidence, slm_confidence)
intel = union(rule_intel, slm_missed_entities)    # dedup
reply = slm_reply if valid else rule_reply         # quality check
agentNotes += slm_insight                          # appended
```

### Performance Impact
| Metric | SLM Off | SLM On |
|---|---|---|
| Avg response | 1.5ms | 300-3000ms (CPU) |
| Max response | 32ms | 8000ms (timeout) |
| Memory | ~50MB | ~350MB |
| Failure mode | N/A | Silent fallback to rules |

---

## ğŸ“ File Structure (v4.4.0)

```
src/
â”œâ”€â”€ main.py              # Orchestrator (7-layer pipeline, v4.4.0)
â”œâ”€â”€ config.py            # Env vars: USE_SLM, SLM_MODEL_PATH, SLM_TIMEOUT
â”œâ”€â”€ slm_engine.py        # NEW â€” SmolLM2 async singleton
â”œâ”€â”€ scam_detector.py     # Rule-based scam detection (16 categories)
â”œâ”€â”€ intelligence.py      # Regex intel extraction (9 fields)
â”œâ”€â”€ fraud_model.py       # GaussianNB fraud model (JP Morgan)
â”œâ”€â”€ agent_persona.py     # Reply engine (600+ templates, dedup, probes)
â”œâ”€â”€ session_manager.py   # In-memory session state machine
â”œâ”€â”€ response_dataset.py  # 400+ English templates
â”œâ”€â”€ hinglish_dataset.py  # 200+ Hinglish templates  
â”œâ”€â”€ models.py            # Pydantic models
â”œâ”€â”€ guvi_callback.py     # Async GUVI reporting
â””â”€â”€ ml_detector.py       # Optional lightweight ML classifier

tests/
â”œâ”€â”€ test_scoring.py      # 32 rubric checks
â”œâ”€â”€ test_edge_cases.py   # 56 adversarial checks
â”œâ”€â”€ test_slm.py          # NEW â€” 41 SLM integration checks
â”œâ”€â”€ test_slm_scenario.sh # NEW â€” 10-turn SLM comparison
â””â”€â”€ ...                  # 5 more suites
```

---

## ğŸ¯ Design Philosophy

1. **Rules First, AI Second** â€” Deterministic pipeline guarantees rubric compliance; SLM only refines
2. **Toggle-Safe** â€” `USE_SLM=false` gives identical behavior to v4.3.0
3. **Fail-Silent** â€” SLM errors never crash the pipeline; rules always have the last word  
4. **Async Non-Blocking** â€” SLM runs in thread pool with hard timeout
5. **Rubric-Maximized** â€” Every GUVI field populated every turn, regardless of SLM state
